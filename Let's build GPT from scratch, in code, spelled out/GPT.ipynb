{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 32 1089k   32  351k    0     0   957k      0  0:00:01 --:--:--  0:00:01  980k\n",
      "100 1089k  100 1089k    0     0  2530k      0 --:--:-- --:--:-- --:--:-- 2581k\n"
     ]
    }
   ],
   "source": [
    "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "!curl -O https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read & inspect textfile\n",
    "with open('input.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"Lenght of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# Unique characters that occur in text:\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 40, 41, 42, 1, 58, 46, 43, 56, 43]\n",
      "Abcd there\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from characters to integers\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: \"\".join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"Abcd there\"))\n",
    "print(decode(encode(\"Abcd there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\olofj\\Code\\GPT\\Let's build GPT from scratch, in code, spelled out\\GPT.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olofj/Code/GPT/Let%27s%20build%20GPT%20from%20scratch%2C%20in%20code%2C%20spelled%20out/GPT.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Encode the entire text dataset and store it into a torch.Tensor\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/olofj/Code/GPT/Let%27s%20build%20GPT%20from%20scratch%2C%20in%20code%2C%20spelled%20out/GPT.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39m# PyTorch: https://pytorch.org\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olofj/Code/GPT/Let%27s%20build%20GPT%20from%20scratch%2C%20in%20code%2C%20spelled%20out/GPT.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(encode(text), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olofj/Code/GPT/Let%27s%20build%20GPT%20from%20scratch%2C%20in%20code%2C%20spelled%20out/GPT.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(data\u001b[39m.\u001b[39mshape, data\u001b[39m.\u001b[39mtype)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch # PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.type)\n",
    "print(data[:1000]) # The 1000 characters we looked at earlier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\olofj\\Code\\GPT\\Let's build GPT from scratch, in code, spelled out\\GPT.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/olofj/Code/GPT/Let%27s%20build%20GPT%20from%20scratch%2C%20in%20code%2C%20spelled%20out/GPT.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "     -------------------------------------- 203.1/203.1 MB 5.4 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 14.2 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp311-cp311-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 14.1 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Collecting sympy==1.13.1\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\olofj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.24.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\olofj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.16.1 fsspec-2024.12.0 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1 typing-extensions-4.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'c:\\Users\\olofj\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe, torchfrtrace.exe and torchrun.exe are installed in 'c:\\Users\\olofj\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (124834019.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[29], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    C:\\Users\\olofj\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
